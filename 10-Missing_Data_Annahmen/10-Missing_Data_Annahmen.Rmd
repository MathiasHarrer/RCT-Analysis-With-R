---
title: Evaluation Randomisiert-Kontrollierter Studien und Experimente mit \textsf{R}
subtitle: Missing Data
author: Prof. Dr. David Ebert & Mathias Harrer
date: Graduiertenseminar TUM-FGZ
institute: Psychology & Digital Mental Health Care, Technische Universität München
output: binb::metropolis
fontsize: 11pt
bibliography: assets/bib.bib
csl: assets/apa.csl
monofont: "Fira Code"
mainfont: "Fira Sans"
header-includes: |
  ```{=latex}
  \usepackage{calc}
  \usepackage{mathspec}
  \usepackage{booktabs}
  \usepackage{amsmath,amsthm}
  \makeatletter
  \let\@@magyar@captionfix\relax
  \makeatother
  \usepackage{xcolor}
  \usepackage{tikz}
  \definecolor{protectBlue}{RGB}{48,124,148}
  \definecolor{protectGreen}{RGB}{161, 198, 66}
  \definecolor{verywhite}{rgb}{1, 1, 1}
  \usepackage{multicol}
  \hypersetup{colorlinks,citecolor=protectGreen,
    filecolor=red,linkcolor=protectGreen,urlcolor=blue}
  \setbeamercolor{progress bar}{fg=protectGreen}
  \setbeamercolor{alerted text}{fg=protectGreen}
  \setbeamercolor{frametitle}{bg=protectBlue}
  \setbeamercolor{normal text}{fg=protectBlue}
  \titlegraphic{%
  \hspace*{6cm}~%
  \includegraphics[width=2cm]{assets/logo/tum-lightblue}
  \hspace*{0.3cm}~%
  \includegraphics[width=2cm]{assets/logo/protect}}
  \setbeamertemplate{frame footer}{Evaluation Randomisiert-Kontrollierter Studien und Experimente mit \textsf{R}}%         <- !!SET FOOTER TITLE!!
  \makeatletter
  \setlength{\metropolis@frametitle@padding}{2.2ex}
  \setbeamertemplate{footline}{%
      \begin{beamercolorbox}[wd=\textwidth, sep=0.7ex]{footline}
          \usebeamerfont{page number in head/foot}%
          \usebeamertemplate*{frame footer}
          \hfill%
          \usebeamertemplate*{frame numbering}
      \end{beamercolorbox}%
  }
  \setbeamertemplate{frametitle}{%
    \nointerlineskip%
    \begin{beamercolorbox}[%
        wd=\paperwidth,%
        sep=0pt,%
        leftskip=\metropolis@frametitle@padding,%
        rightskip=\metropolis@frametitle@padding,%
      ]{frametitle}%
    \metropolis@frametitlestrut@start%
    \insertframetitle%
    \nolinebreak%
    \metropolis@frametitlestrut@end%
    \hfill
    \includegraphics[height=2ex,keepaspectratio]{assets/logo/tum_white}
    \end{beamercolorbox}%
  }
  \newlength{\cslhangindent}
  \setlength{\cslhangindent}{1.5em}
  \newenvironment{CSLReferences}[3][0]%
  {\setlength{\parindent}{0pt}%
  \everypar{\setlength{\hangindent}{\cslhangindent}}\ignorespaces}%
  ```
---

```{r,setup, include=FALSE}
knitr::opts_chunk$set(cache=TRUE, comment = "#>", background = '#F7F7F7')
```


# Missing Data-Mechanismen

## Unbequeme Wahrheiten ... (I)

_"Obviously the best way to treat missing data is not to have them."_
\newline \scriptsize @orchard1972missing \par \normalsize

$$~$$

Fehlende Werte sind aber, insbesondere in der medizinischen und psychologischen Forschung, 
häufig **\alert{unvermeidbar}**!

## Unbequeme Wahrheiten ... (II)

\metroset{block=fill} 
\begin{exampleblock}{Taxonomie: Gründe für fehlende Werte in klinischen Studien}
\small
\begin{itemize}
  \item \textbf{Instrumente}: Response Burden, zu langes Assessment, ... 
  \item \textbf{Teilnehmende}: Überforderung, Privatsphäre, Movationsprobleme, ...
  \item \textbf{Center}: Inadäquate Umsetzung des Studienmethodik, Personalmangel, ...
  \item \textbf{Personal}: Falsche Datenerfassung, Datenverlust, falsche Dateneingabe, ...
  \item \textbf{Studie}: Technische Fehler, Zeitverzögerungen bei Follow-Ups, ...
\end{itemize}
\par \normalsize
\end{exampleblock}

\scriptsize @palmer2018systematic \par \normalsize

## Unbequeme Wahrheiten ... (III)

**Der Umgang mit fehlenden Werten in der (medizinisch-psychologischen) Forschung ist oftmals mangelhaft:** \scriptsize [@wood2004missing; @akl2015reporting; @vanbuuren, Kapitel 1.1.2; @bell2014handling] \par \normalsize

- Verteilung fehlender Werte nicht transparent berichtet
- Unpassendes missing data handling (z.B. **\alert{listwise deletion}**)
- Adäquate Imputationsmethoden (z.B. MI, FIML) häufig nicht benutzt, inadäquat angewendet, oder
unzureichend berichtet


## Unbequeme Wahrheiten ... (IV)

**\textsf{R} macht es nicht (automatisch) "richtig"!**

\small

```{r, eval=FALSE, comment="##>", background="green"}
y <- 1:10
x <- c(1, NA, NA, NA, 3, 5, 8, 10, -1, 10)
summary(lm(y ~ x))
```

```
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)  
## (Intercept)   4.9403     1.7738   2.785   0.0387 *
## x             0.3172     0.2709   1.171   0.2945  
## ---
## Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
## 
## Residual standard error: 2.904 on 5 degrees of freedom
##   (3 observations deleted due to missingness)
```
\par \normalsize

## Unbequeme Wahrheiten ... (V)

**Was dagegen tun?**

- Umsetzung von **\alert{Reporting-Standards}** \scriptsize z.B. `STROBE` [@von2007strengthening] & `CONSORT` [@schulz2010consort], s.a. @sterne2009multiple. \par \normalsize
- Adäquates **\alert{Missing Data Handling}**
  - Basierend auf plausiblen Annahmen, warum fehlende Werte enstanden sind ("Missing Data Mechanism")
  - ggf. Schätzung (Imputation) fehlender Werte unter Einbezug von deren Unsicherheit

# MCAR, MAR & MNAR

## MCAR, MAR & MNAR (I)

\begin{multicols}{2}

  \null \vfill
  \includegraphics[width=.3\textwidth]{assets/rubin.jpg}
  \newline Donald B. Rubin
  \vfill \null

\columnbreak

  \null \vfill
  \textbf{Grundannahme}: Das Fehlen oder Vorhandensein von Daten ist Resultat eines probabilistischen Prozesses. \newline \newline
  Diesem Prozess versucht man sich durch ein Modell (\textbf{\emph{missing data model}}) anzunähern. 
  \vfill \null
\end{multicols}

\small [@rubin1976inference] \par \normalsize

## MCAR, MAR & MNAR (II)

\includegraphics[width=1\textwidth]{assets/model_concept_sep.png}

[@harrer2021doing]


## MCAR, MAR & MNAR (III)

\small

Nach @rubin1976inference können Missing Data-Mechanismen in 3 Untertypen klassifiziert werden: 

\metroset{block=fill} 

\begin{exampleblock}{MCAR}
  Missing Completely At Random: rein zufällig fehlende Werte einer Variable.
\end{exampleblock}

\begin{exampleblock}{MAR}
  Missing At Random: das Fehlen von Werten einer Variable ist abhängig von anderen (observierten) Variablen.
\end{exampleblock}

\begin{exampleblock}{MNAR}
  Missing Not At Random / "Nonignorable Missing Data": das Fehlen von Werten Variable ist (u.A.) abhängig von den Werten der Variable selbst.
\end{exampleblock}

&rightarrow; Für jede Annahme ergeben sich unterschiedliche Auswirkungen bei der Datenauswertung!

\par \normalsize

## MCAR, MAR & MNAR (IV)

**Notation** \scriptsize [@vanbuuren, Kapitel 2.2.3 & 2.2.4] \par \normalsize

- $\mathbf{Y}$: $n\times p$ Matrix mit teils fehlenden Werten ($n$ Personen, $p$ Variablen).
- $\mathbf{X}$: Matrix mit (vollständig observierten) Kovariaten.
- $\mathcal{D} = (\mathbf{Y}, \mathbf{X})$: Gesamter Datensatz.
- $\mathbf{R}$: $n\times p$ Matrix mit 0 (Datenpunkt fehlt) und 1 (Datenpunkt observiert; "response indicator").
- $\mathbf{Y}_{\text{obs}}$, $\mathbf{Y}_{\text{mis}}$: Observierte Daten, fehlende Daten.
- $\psi$: Parameter des Missing Data-Modells (typischerweise nicht für die wiss. Fragestellung selbst relevant).

&rightarrow; Missing Data-Modelle treffen Aussagen darüber, **\alert{in welcher Beziehung}** $\mathbf{Y}_{\text{obs}}$, $\mathbf{Y}_{\text{mis}}$ und $\mathbf{R}$ miteinander stehen. 


## MCAR, MAR & MNAR (V)

**MCAR**

$$P(\mathbf{R}=0|\mathbf{Y}_{\text{obs}}, \mathbf{Y}_{\text{mis}}, \psi) \Rightarrow P(\mathbf{R}=0|\psi)$$
Werte in $\mathbf{Y}$ fehlen "zufällig" (unabhängig von Werten von $\mathbf{Y}$). Das Fehlen von Werten ist nur bestimmt durch die allgemeine Wahrscheinlichkeit, dass Werte fehlen (im Datensatz gab es eher viele oder wenige Missings). \linebreak


\metroset{block=fill} 

\begin{exampleblock}{Beispiel}
  Das Fehlen der Variable "Alter" ist weder von der Variable "Neurotizismus", noch vom Alter der Person selbst abhängig.
\end{exampleblock}


## MCAR, MAR & MNAR (VI)

**MAR**

$$P(\mathbf{R}=0|\mathbf{Y}_{\text{obs}}, \mathbf{Y}_{\text{mis}}, \psi) \Rightarrow P(\mathbf{R}=0|\mathbf{Y}_{\text{obs}}, \psi)$$

Werte in $\mathbf{Y}$ fehlen abhängig von $\psi$ **und** **\alert{observierter}** Information $\mathbf{Y}_{\text{obs}}$. \linebreak


\metroset{block=fill} 

\begin{exampleblock}{Beispiel}
  Personen mit höheren Neurotizismus-Werten geben ihr Alter seltener an als Personen mit niedrigem Neurotizismus, unabhängig ihres Alters.
\end{exampleblock}


## MCAR, MAR & MNAR (VII)

**MNAR**

$$P(\mathbf{R}=0|\mathbf{Y}_{\text{obs}}, \mathbf{Y}_{\text{mis}}, \psi) \Rightarrow~?$$
_Die Formel lässt sich nicht "vereinfachen" !_

Werte in $\mathbf{Y}$ fehlen abhängig von $\psi$, observierter Information $\mathbf{Y}_{\text{obs}}$, **und** der **\alert{unobservierten Information}** $\mathbf{Y}_{\text{mis}}$ selbst. \linebreak


\metroset{block=fill} 

\begin{exampleblock}{Beispiel}
  Das Fehlen der Alters-Variable hängt (u.A.) vom Alter der Person selbst ab. Eventuell geben ältere Personen mit hohem Neurotizismus ihr Alter seltener an. \textbf{Aber das wissen wir nicht}, da die Daten fehlen!
\end{exampleblock}


## MCAR, MAR & MNAR (VIII)


**Observierte und unobservierte Werte unter drei Missing Data-Annahmen**

\includegraphics[width=0.8\textwidth]{assets/buuren-mechanisms.png}

aus @vanbuuren, Kapitel 2.2.4


## MCAR, MAR & MNAR (IX)

**Implikationen**

- **MCAR**: Da die Werte zufällig fehlen, ist beim Einsatz passender statistischer Verfahren keine Verzerrung der Ergbnisse zu erwarten. Es besteht kein systematischer **\alert{Bias}**; nur ein Verlust der statistischen Power durch den Datenverlust.
- **MAR**: Bei der Schätzung von Parametern ergeben sich evtl. Verzerrungen (Bias), wenn die abhängigen Variablen nicht im Modell berücksichtigt werden. Werden die abhängigen Variablen adäquat mit einbezogen, können Verzerrungen vermieden werden.


## MCAR, MAR & MNAR (X)


- **MNAR**: Bei der Schätzung von Parametern ergeben sich Verzerrungen. Da das Fehlen von Werten von den fehlenden Werten selbst abhängig ist, können nur "best guesses" hinsichtlich des **\alert{zugrundeliegenden Dropout-Mechanismus}** getroffen werden. Ob diese korrekt sind, kann nicht empirisch überprüft werden. 

## MCAR, MAR & MNAR (XI)

Beim Vorliegen von MNAR spricht man von **\alert{"nonignorable missing data"}** [@little2019statistical]. Dies bedeutet, dass \underline{nicht} von der gemeinsamen (Posterior-)**Verteilung der observierten Daten auf die der fehlenden Daten geschlossen werden kann**:

$$P(\mathbf{Y}|\mathbf{Y}_{\text{obs}}, \mathbf{R}=1) \neq P(\mathbf{Y}|\mathbf{Y}_{\text{obs}},\mathbf{R}=0)$$

Das impliziert, dass eine Schätzung (Imputation) auf Basis der vorliegenden Werte nicht ohne weiteres möglich ist. Es müssen Annahmen getroffen werden, die **\alert{"über die Daten hinaus gehen"}**. 

## MCAR, MAR & MNAR (XII)

**Was bedeutet das für die Analyse von RCT-Daten?**

\begin{center}
\alert{\textbf{MCAR}}
\end{center}

- Complete Case-Analysen und andere Ad Hoc-Verfahren führen nicht zu einer systematischen Verzerrung der Ergebnisse (aber durchaus zu einem Verlust statistischer Power/"Effizienz"). 

- Die MCAR-Annahme ist typischerweise für RCT-Daten **\alert{nicht sehr plausibel}**. \scriptsize [@bell2014handling; @mallinckrodt2004choice] \par \normalsize

- Selbst wenn die MCAR-Annahme zutrifft, können Verfahren wie Multiple Imputation genutzt werden, z.B. um Konfidenzintervalle korrekter zu schätzen. \scriptsize [vgl. @pedersen2017missing] \par \normalsize


## MCAR, MAR & MNAR (XIII) {.t}

**Was bedeutet das für die Analyse von RCT-Daten?**

\begin{center}
\alert{\textbf{MAR}}
\end{center}

- Complete Case-Analysen führen zu einer Verzerrung der Ergebnisse. 
- Verfahren wie Multiple Imputation, Full Information Maximum Likelihood (FIML) oder Mixed-Effect Models (eingeschränkt) können aber **\alert{genutzt werden, um die MAR-Annahme abzubilden}**. 
- Werden diese Modelle korrekt angewandt, vermeidet dies gebiaste Ergebnisse und führt zu einem korrekten Miteinbezug der Unsicherheit durch fehlende Werte (&rightarrow; passende Konfidenzintervalle).

## MCAR, MAR & MNAR (XIV) {.t}


**Was bedeutet das für die Analyse von RCT-Daten?**

\begin{center}
\alert{\textbf{MNAR}}
\end{center}

- Auch Verfahren wie Multiple Imputation (denen nur die observierten Daten zugrunde liegen) können zu **\alert{Verzerrungen in den Ergebnissen führen}**. 
- Methoden wie **Pattern-Mixture/Selektionmodelle** oder **referenzbasierte Imputation** können genutzt werden, um die Ergebnisse unter Annahme bestimmter Dropout-Mechanismen zu analysieren. \scriptsize [@little2019statistical, Kapitel 15; @heckman1976common; @carpenter2013analysis] \par \normalsize 
- Diese Annahmen sind jedoch nicht direkt empirisch nachweisbar.


## MCAR, MAR & MNAR (XV) 


_"MNAR models are [...] typically **\alert{highly dependent on untestable and often implicit assumptions}** regarding the
distribution of the unobserved measurements given the observed measurements."_


\textemdash @molenberghs2004analyzing, S. 447




## MCAR, MAR & MNAR (XVI) 

\alert{\textbf{Was soll ich für meinen Trial annehmen?}}


_"[W]e recommend that in trials [...], all data should be used in an analysis that makes a plausible assumption about missing data. Usually this will be a MAR assumption."_

\footnotesize
\textemdash @bell2014handling \par \normalsize

_"The assumption of ignorability is often sensible in practice, and generally provides a natural starting point."_

\footnotesize
\textemdash @vanbuuren, Kapitel 2.2.6 \par \normalsize

## Zusammenfassung

- Dropout & Fehlende Daten sind bei RCTs **kaum zu vermeiden**.

- Das Fehlen von Daten kann man sich als **"Produkt" eines wahrscheinlichkeitsbasierten Prozesses** vorstellen, der von einem (realen oder angenommenen) **Missing Data-Mechanismus** gesteuert wird.

- Derartige Mechanismen lassen sich in drei "Archetypen" zusammenfassen: **MCAR**, **MAR** und **MNAR**.

- Wird der zugrundeliegende Missing Data-Mechanismus \underline{nicht} berücksichtigt, kann dies bei der Analyse zu **Verzerrungen** und **falschen Schlußfolgerungen** führen.

\begin{tikzpicture}[remember picture,overlay]  
  \node [xshift=-0.7cm,yshift=-8.7cm] at (current page.north east)
    {\includegraphics[width=1cm,height=1cm]{assets/summary.png}};
\end{tikzpicture}

## Zusammenfassung


- Ob Daten MAR oder MNAR sind, kann **\underline{nicht} anhand der Daten selbst bestimmt werden**; beide Annahmen sind immer nur mehr oder weniger plausibel.

- Bei RCTs ist die **Annahme von MAR häufig ein guter Startpunkt**; die Ergebnisse im Fall von nonignorable missing data (MNAR) können dann z.B. durch Sensitivitätsanalysen geprüft werden [@bell2014handling].

- Insbesondere **multiple Imputationsverfahren** sind ein gutes Mittel, Verzerrungen der Ergebnisse durch Dropout unter Annahme von MAR vorzubeugen.


\begin{tikzpicture}[remember picture,overlay]  
  \node [xshift=-0.7cm,yshift=-8.7cm] at (current page.north east)
    {\includegraphics[width=1cm,height=1cm]{assets/summary.png}};
\end{tikzpicture}

## Zusammenfassung

\footnotesize

\metroset{block=fill} 

\begin{exampleblock}{Kurze Anmerkung zu Little's MCAR Test}
\begin{itemize}
  \item Der $\chi^2$ MCAR Test von Little findet immer noch häufig bei der Analyse von RCT Verwendung.
  \item Die Nullhypothese ist hierbei, dass Missings in den Daten zufällig auftreten \\ ($\rightarrow$ MCAR). 
  \item Der \textbf{praktische Nutzen dieses Tests ist häufig begrenzt}: die Fähigkeit des Tests, die Nullhypothese (MCAR) zu verwerfen, hängt von der Größe des Datensets, und damit der statistischen Power ab. Bei großen Datensets können schon kleine Abweichungen zu einem Wert $p$<0.05 führen.
  \item Ein signifikanter MCAR-Test sagt nichts darüber, ob die Daten MAR oder MNAR sind!
  \item \alert{\textbf{Tipp:}} stattdessen MAR als plausiblen "first start" annehmen, MNAR-Auswirkungen ggf. durch Sensitivitätsanalysen explorieren.
  \end{itemize}
\end{exampleblock}

siehe @little1988test.

\par \normalsize

# Multiple Imputation

## Multiple Imputation (I)

- Multiple Imputation [**\alert{MI}**, @rubin1987multiple] ist eine der flexibelsten und **gängigsten Methoden** zum Umgang mit fehlenden Werten. \linebreak

- **Ziel von MI**: auf Basis der Verteilung der beobachteten Daten plausible Werte für die fehlenden Werte schätzen ("imputieren"). \linebreak

- Um die Unsicherheit bei der Schätzung fehlender Werte abzubilden, werden **mehrere ("multiple") Imputationen** für jeden fehlenden Datenpunkt erzeugt. \linebreak

- Die so generierten vollständigen Datensätze werden dann **simultan analysiert** (z.B. Berechnung des Stichprobenmittelwerts) und Ergebnisse abschließend **gepoolt**.



## Multiple Imputation (II)


\includegraphics[width=1\textwidth]{assets/mi.png}

\scriptsize

aus @van2011mice.

\par \normalsize

## Multiple Imputation (III)

- MI kann unter **Annahme von MCAR und MAR** (sowie unter bestimmten Voraussetzungen auch MNAR) verwendet werden. \linebreak

- Wenn korrekt angewandt, führt MI zur **\alert{verzerrungsfreien Schätzung von Populationsparametern}** (Regressionsgewichte, Populationsmittelwerte, Korrelationen, etc.) sowie deren Varianz ("asymptotically unbiased") --- trotz des Vorliegens fehlender Werte. \scriptsize [@white2011multiple] \par \normalsize



## Multiple Imputation (IV)

**Es können 2 MI-Ansätze unterschieden werden:**

- **\alert{Joint Modeling (JM)}**: Spezifikation einer multivariaten Verteilung ("joint model") für die fehlenden Daten, auf deren Basis Imputationen mit Markov Chain Monte Carlo (MCMC) gesampelt werden [@schafer1997analysis]. 

- **\alert{Fully Conditional Specification (FCS)}**: unvollständige Variablen werden in einem sequentiell-iterativen Prozess imputiert, eine Variable nach der Anderen. 

Für FCS ist es im Gegensatz zu JM nicht notwendig, eine multivariate Verteilung der fehlenden Daten zu finden. FCS ist in dieser Hinsicht "atheoretisch" [vgl. @white2011multiple]. 


## Multiple Imputation (V)

**Der `MICE` Algorithmus**

Der **\alert{`MICE`}** (_Multiple Imputation by Chained Equations_) Algorithmus ist eine der am häufigsten verwendeten und am besten erprobten FCS-Ansätze. \newline

_"The MICE algorithm possesses a touch of magic."_

\scriptsize
\textemdash @van2011mice \par \normalsize


## Multiple Imputation (VI)


\small

**Die Idee der "Chained Equations"**

Annahme: unsere Daten $\mathbf{Y} = Y_1, Y_2, ..., Y_p$ (teils vorliegend, teils fehlend) sind das "Produkt" von $\mathbf{\theta}$, einem (unbekannten) Vektor von Populationsparametern. Der multivariaten Verteilung von $\mathbf{\theta}$ wollen wir uns annähern, um korrekte Imputationen zu erzeugen.

Der `MICE` Algorithmus tut dies implizit, indem er iterativ für jede einzelne unvollständige Variable $Y$ aus deren bedingter Verteilung sampelt, in folgender Form [@van2011mice]:

\begin{align*}
\begin{split}
& P(Y_1|\mathbf{Y}_{\setminus1}, \mathbf{\theta}_1) \\
& \vdots \\
& P(Y_p|\mathbf{Y}_{\setminus p}, \mathbf{\theta}_p)
\end{split}
\end{align*}

\par \normalsize


## Multiple Imputation (VII)

Dies wird durch sogenanntes **\alert{Gibbs-Sampling}** umgesetzt. Basierend auf Ausgangswerten wird dabei iterativ für jede Variable $j$ jeweils zuerst $\mathbf{\theta}_j$ geschätzt, was wiederum direkt genutzt wird, um imputierte Werte $Y^*_j$ zu erzeugen. Diese Werte bilden dann die Basis für das weitere Sampling. 

**Für eine beliebige Iteration $t$ ergibt sich so:**


\begin{align*}
\begin{split}
\theta^{*t}_1 &\sim P(\theta_1|Y^{\text{obs}}_1, Y_2^{t-1}, \dots, Y_p^{t-1}) \\
Y^{*t}_1 &\sim P(Y_1|Y^{\text{obs}}_1, Y_2^{t-1}, \dots, Y_p^{t-1}, \theta_1^{*t}) \\
&\vdots \\
\theta^{*t}_p &\sim P(\theta_p|Y^{\text{obs}}_p, Y_1^{t}, \dots, Y_{p-1}^{t}) \\
Y^{*t}_p &\sim P(Y_p|Y^{\text{obs}}_p, Y_1^{t}, \dots, Y_{p-1}^{t}, \theta_{p}^{*t})
\end{split}
\end{align*}

## Multiple Imputation (VIII)

Im Normalfall **\alert{konvergiert}** dieser Prozess nach einer bestimmten Anzahl Iterationen und erreicht Stationarität ("pendelt sich ein"). 

Da in `MICE` die vorherige Imputation $Y_j^{t-1}$ zur Imputation von $Y_j$ nicht direkt einfließt, wird dies **relativ schnell erreicht** (oft schon nach 5-10 Iterationen).

Dieser iterative Prozess wird **parallel mehrfach durchgeführt**, um die $m$ Imputationssets zu erzeugen.



## Multiple Imputation (IX)

Die genaue Technik, mit der die Imputationen erzeugt werden, kann bei `MICE` **\alert{flexibel für jede Variable festgelegt werden}**:

```{r, echo=F}

df = data.frame(
  Technik = c("Predictive Mean Matching", 
              "Bayesian Linear Regression", 
              "Uncodition Mean Imputation",
              "Bayesian Logistic Regression", 
              "Bayesian Polytomous Regression"),
  Implementierung = c("\\texttt{pmm}", "\\texttt{norm}", "\\texttt{mean}", "\\texttt{logreg}", "\\texttt{polyreg}"),
  Skala = c("sämtliche", "kontinuierlich", "kontinuierlich",
            "binär", "faktoriell"))

knitr::kable(df, booktabs = TRUE, escape = FALSE) %>% 
  row_spec(0, bold = TRUE)
```

\footnotesize

Typische Techniken zur Imputation mit `MICE`, nach Skalentyp. \par \normalsize

## Multiple Imputation (X)

**Predictive Mean Matching (PMM)**

- PMM [@morris2014tuning] ist eine sogenannte "Hot Deck"-Methode.

- Dabei werden fehlende Werte anhand der eines **\alert{"Spenders"}** imputiert.

- Der Spender wird dabei zufällig aus einer Anzahl von Kandidaten ausgewählt, die der Person mit fehlenden Werten **statistisch "ähnlich"** sind (d.h. ähnliche vorhergesagte Werte hat):

$$\text{arg min}_{i}~\left|\hat{y}^{\text{(obs)}}_i-\hat{y}^{\text{(mis)}}_j\right|$$


- Eine Anzahl von $d=$ 3-10 Spenderkandidaten ist dabei häufig passend [@morris2014tuning].

## Multiple Imputation (XI)

\includegraphics[width=0.68\textwidth]{assets/pmm.png}

\footnotesize [@vanbuuren, Kapitel 3.4.1] \par \normalsize


## Multiple Imputation (XII) {.t}


**Predictive Mean Matching (PMM)**

- PMM ist eine breit einsetzbare und typischerweise **robuste Technik** zur Imputation [@kleinke2017multiple].

- Da alle Werte von beobachteten Spendern stammen, ist das Imputieren **\alert{"unmöglicher" Werte}** (z.B. Alter von -2) **\alert{ausgeschlossen}**.


## Multiple Imputation (XIII)

\small

\metroset{block=fill} 

\begin{exampleblock}{Multiple Imputation: Praktische Fragen}
  \begin{itemize}
  \item \textbf{\alert{Anzahl der Imputationssets?}} $m=$ 20 Sets sind häufig ausreichend bei moderater Menge an Missings. Mehr (z.B. $m \approx$ 50-100) sind notwendig, um schwer zu schätzende Parameter (z.B. Standardfehler, Varianzkomponenten) genau zu schätzen; oder wenn zahlreiche Missings vorliegen (van Buuren, 2018, Kapitel 2.8).  
  \item \textbf{\alert{Anzahl der Iterationen?}} 20-30 Iterationen häufig bereits ausreichend; dies kann erhöht werden, wenn Konvergenz in Frage steht. 
  \item \textbf{\alert{Breite des Imputationsmodells?}} "So breit wie möglich, so schmal wie nötig". Eine breite Auswahl von (sinnvollen) "Hilfsvariablen" macht die MAR-Annahme plausibler, kann aber zu Softwareproblemen führen ($\rightarrow$ zu hohe Komplexität). Deshalb: "goldene Mitte" finden, Modellkomplexität reduzieren, ohne die Plausibilität des Modells zu sehr zu vermindern.
  \end{itemize}
\end{exampleblock}

\par \normalsize

## Multiple Imputation (XIV)


_"In general, one should try to **\alert{simplify the imputation structure without damaging it}**; for example, omit variables that seem on exploratory investigation unlikely to be required in ‘reasonable’ analysis models, but avoid omitting variables that are in the analysis model or variables that clearly contribute towards satisfying the MAR assumption."_

\scriptsize

--- @white2011multiple \par \normalsize




## $~$

\begin{tikzpicture}[remember picture,overlay]  
  \node [xshift=0cm,yshift=-0.6cm] at (current page.center)
    {\includegraphics[width=1.05\paperwidth]{assets/bg-praxis.jpg}};
\end{tikzpicture}

\Huge
\colorbox{white}{\textbf{ Praxis-Teil }} \par \normalsize 

$$~$$
$$~$$

$$~$$

$$~$$

$$~$$

## Influx & Outflux (I)

Der **\alert{Influx-}** & **\alert{Outflux-Koeffizient}** kann genutzt werden, um potenziell (un-)relevante Prädiktoren für das Imputationsmodell zu identifizieren.

Bei gleicher Anzahl von Missings zeigen diese Koeffizienten an, welche Variablen besser mit dem Rest der (beobachteten) Daten "verbunden" sind.

Bei RCTs ist der heuristische Werte der Koeffizienten oft begrenzt, da Daten Zeitpunkt-abhängig fehlen (z.B. fehlen für Person $i$ durch Dropout sämtliche Daten zum Postzeitpunkt).

\scriptsize [@vanbuuren, Kapitel 4.1.3] \par \normalsize

## Influx & Outflux (II)

Der **\alert{Influx-Koeffizient}** $I_j$ einer Variable $j$ gibt an, wie gut _fehlende_ Werte in $j$ durch _beobachtete_ Werte in anderen Variablen abgedeckt werden.

\small
Es sei $R_{ij}$ der Responseindikator (beobachtet = 1; fehlend = 0) für Person $i$ bei Variable $j$. $R_{ik}$ sei der Indikator für selbige Person bei einer beliebigen anderen Variable $k$. \par \normalsize

**Für den Influx-Koeffizienten von $j$ ergibt sich so:**

$$I_j = \frac{\sum_j^p\sum_k^p\sum_i^n (1-R_{ij})R_{ik}}{\sum_k^p\sum_i^n R_{ik}}$$

\scriptsize [@vanbuuren, Kapitel 4.1.3] \par \normalsize


## Influx & Outflux (III)

Der **\alert{Outflux-Koeffizient}** $O_j$ einer Variable $j$ gibt an, wie gut _beobachtete_ Werte in $j$ zur Abeckung _fehlender_ Werte in anderen Variablen genutzt werden können.

**Für Variable $j$ ergibt sich so:**

$$O_j = \frac{\sum_j^p\sum_k^p\sum_i^n R_{ij}(1-R_{ik})}{\sum_k^p\sum_i^n 1-R_{ij}}$$

## Der "Fluxplot"

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.width=5, fig.height=5.5, out.width= "50%", fig.align='center'}
library(mice)
read.csv("data/data.csv") -> data
fluxplot(data, main = "")

```

\scriptsize
Werte im **\alert{oberen Bereich}** sowie nah an der Diagonalen sind eher hilfreich als Prädiktoren. Werte im **\alert{unteren linken Bereich}** können eher entfernt werden (insofern inhaltlich nicht/wenig relevant). \newline \textbf{CAVE: Der Flux-Koeffizient sagt nichts über die tatsächliche Vorhersagekraft der Variable aus!} \par \normalsize


## Diagnostik des Imputationsmodells (I)

**\alert{Beispiel für Nonkonvergenz:}** Chains vermischen sich kaum & zeitlicher Trend ersichtlich!

\includegraphics[width=0.68\textwidth]{assets/nonconvergence.png}

\footnotesize [@vanbuuren, Kapitel 6.5.2] \par \normalsize

## Diagnostik des Imputationsmodells (II)

- Typischerweise sollte ein plausibles Imputationsmodell Werte $\dot{\mathbf{Y}}_{\text{mis}}$ erzeugen, die in ihrer Verteilung denen von $\mathbf{Y}_{\text{obs}}$ ähneln.

- Unter MAR sind jedoch auch **\alert{systematische Unterschiede}** zwischen $\dot{\mathbf{Y}}_{\text{mis}}$ und $\mathbf{Y}_{\text{obs}}$ plausibel (z.B. Mittelwerts- oder Streuungsunterschiede)!

- Besonders **\alert{starke Divergenzen}** sowie ausgesprochen unplausible/extreme Ergebnisse können jedoch auf Probleme des Imputationsmodells hinweisen.


# Referenzen

## Referenzen {.allowframebreaks}

\scriptsize





